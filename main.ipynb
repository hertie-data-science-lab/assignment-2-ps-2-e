{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "# Problem set 2\n",
        "\n",
        "## Team\n",
        "Please write here your names and team number.\n",
        "\n",
        "* Team name: ps-2-e\n",
        "* Team members: Xiaohan Wu, Benjamin Adoba Ayida, Giulia Petrilli\n",
        "\n",
        "\n",
        "## Using Colab with GitHub\n",
        "To utilize GPU support for model training, we highly recommend to open this notebook with Google Colab. Simply, change the domain from 'github.com' to 'githubtocolab.com' and refresh the site to open the notebook in Colab.\n",
        "If you haven't used Colab before with private repositories, make sure to grant Colab access to your private repositories (see screenshot) and after that just try to change the domain again.\n",
        "\n",
        "Finally, you should make sure that you add a GPU to your Colab notebook. You can do so by clicking on `Runtime` →  `Change runtime type` → `Hardware accelerator`  →  `GPU`.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Make sure that you always commit and push the changes you make in Colab back to GitHub. To do so from within a Colab notebook, click `File` → `Save a copy in GitHub`. You will be prompted to add a commit message, and after you click OK, the notebook will be pushed to your repository. Only changes that are visible in your GitHub repository on the main branch will be considered for grading. If you close Colab in your browser without pushing your changes to GitHub or saving them on Google Drive, they will be lost.\n",
        "\n",
        "Make sure that all your work has been pushed to GitHub before the deadline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffVUKx7P6RD"
      },
      "source": [
        "Check that the GPU  enabled in your colab notebook by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPzhNed7P2i9",
        "outputId": "f7b76d9b-a77b-44a5-a290-4220780752cd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Check is GPU is enabled\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "\n",
        "# Get specific GPU model\n",
        "if str(device) == \"cuda:0\":\n",
        "  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29zJt4eFI25Y"
      },
      "source": [
        "You will be working with the EuroSAT dataset. The dataset contains 8489 pictures of 3 different land coverage types (crop, herbaceous vegetation and river). Running the lines below will download the data and return a random picture from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "7MgSuuP3Kjx0",
        "outputId": "4bfd3dc1-15c0-4eec-b0bc-19adc493c258"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import EuroSAT\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data = EuroSAT(root=os.getcwd(), download=True) #downloads the dataset to your current directory\n",
        "print(f\"The dataset has {len(data)} images\")\n",
        "randint = np.random.randint(len(data))\n",
        "\n",
        "pic, tar = data[randint]\n",
        "print(f\"Picture number {randint} with label: {tar}\")\n",
        "pic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99jkSa_KmrDH"
      },
      "source": [
        "# Task 1: Transform the data (10 pt)\n",
        "\n",
        " Your task is to train a classifier to classify the different land usage types in the dataset.\n",
        "- Implement the class `rotate` that maps pictures to flipped pictures by 90, 180, 270 or 360°. The class should return an error if you try to rotate the picture by other degrees.\n",
        "- Plot a histogram with the frequencies of each class. Make sure to insert both name and label in the histogram (e.g. `AnnualCrop:0`).\n",
        "- We create a class `RotateEuroSAT` that takes as input the original dataset and returns a new dataset which contains randomly rotated pictures and whose label proportion can be customized.\n",
        "Implement the class method `_create_rotated_dataset` that returns this pictures using the previously implemented `rotate`.\n",
        "- `RotateEuroSAT` should also take care of transforming the pictures to tensors and optionally move the tensor to a GPU device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "43onRqgGmalG",
        "outputId": "d87530cb-d3df-47a7-ea35-408281dd9edb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def rotate_picture(picture, rotation):\n",
        "  '''#TODO: implemented most frequent n people'''\n",
        "  # PIL uses predefined constants for transpose operations\n",
        "  if rotation == 90:\n",
        "    return picture.transpose(Image.ROTATE_90)\n",
        "  elif rotation == 180:\n",
        "    return picture.transpose(Image.ROTATE_180)\n",
        "  elif rotation == 270:\n",
        "    return picture.transpose(Image.ROTATE_270)\n",
        "  elif rotation == 360:\n",
        "    # 360 degrees rotation is no change\n",
        "    return picture\n",
        "  else:\n",
        "    raise ValueError(f\"Invalid rotation degree: {rotation}. Must be 90, 180, 270, or 360.\")\n",
        "\n",
        "\n",
        "def plot_histogram(data):\n",
        "  # extract all labels from the dataset\n",
        "  labels = [data[i][1] for i in range(len(data))]\n",
        "\n",
        "  # Count the frequency of each label\n",
        "  unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "  try:\n",
        "    class_names = data.classes\n",
        "  except AttributeError:\n",
        "    class_names = [f\"Class_{i}\" for i in unique_labels]\n",
        "\n",
        "  # Create labels for the histogram: Name:Label\n",
        "  x_labels = [f\"{class_names[i]}:{i}\" for i in unique_labels]\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "  # Plot the histogram\n",
        "  bars = ax.bar(x_labels, counts, color='skyblue', edgecolor='black')\n",
        "\n",
        "  # Add value labels above each bar\n",
        "  for bar, count in zip(bars, counts):\n",
        "      height = bar.get_height()\n",
        "      ax.text(\n",
        "          bar.get_x() + bar.get_width() / 2,  # x position (center of bar)\n",
        "          height + max(counts) * 0.01,        # y position (slightly above bar)\n",
        "          f\"{int(count)}\",                    # text (count)\n",
        "          ha='center', va='bottom', fontsize=10, color='black'\n",
        "      )\n",
        "\n",
        "  # Add titles and labels\n",
        "  ax.set_title(\"Class Frequency Histogram (EuroSAT)\", fontsize=14, pad=15)\n",
        "  ax.set_xlabel(\"Class Label and Name\", fontsize=12)\n",
        "  ax.set_ylabel(\"Frequency\", fontsize=12)\n",
        "  plt.xticks(rotation=45, ha='right') # Rotate labels for better fit\n",
        "  plt.tight_layout()\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "new_pic = rotate_picture(pic, 90) # Example of rotating a picture by 90 degrees\n",
        "same_pic = rotate_picture(pic, 360) # Example of rotating a picture by 360 degrees (should return the same picture)\n",
        "fig, ax = plot_histogram(data)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "ErD2pLeyyDf-",
        "outputId": "f2b7614c-4fc6-4a01-dbca-01f7882a7bda"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(pic)\n",
        "axes[0].set_title(\"Original picture\")\n",
        "axes[1].imshow(new_pic)\n",
        "axes[1].set_title(\"Rotated by 90°\")\n",
        "axes[2].imshow(same_pic)\n",
        "axes[2].set_title(\"Rotated by 360°\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD-Ij7cAt_wu"
      },
      "outputs": [],
      "source": [
        "class RotateEuroSAT(Dataset):\n",
        "    def __init__(self,\n",
        "                 original_data:Dataset,\n",
        "                 length:int,\n",
        "                 shares:list,\n",
        "                 device=None,\n",
        "                 seed=42):\n",
        "\n",
        "        self.original_data = original_data\n",
        "        self.length = length\n",
        "        assert sum(shares)  == 1, \"Shares must sum to 1\"\n",
        "        assert len(shares) == len(original_data.classes), \"Shares must match number of classes\"\n",
        "        self.shares = shares\n",
        "        self.seed = seed\n",
        "        self.device = device\n",
        "        self.dataset = self._create_rotated_dataset()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        picture, label = self.dataset[idx]\n",
        "        return picture, label\n",
        "\n",
        "    def _create_rotated_dataset(self):\n",
        "        \"\"\"#TODO: implement solution\"\"\"\n",
        "        np.random.seed(self.seed)\n",
        "        rng = np.random.default_rng(self.seed)\n",
        "\n",
        "        rotations = [90, 180, 270, 360]\n",
        "        dataset = []\n",
        "\n",
        "        # Compute number of samples per class based on shares\n",
        "        samples_per_class = (np.array(self.shares) * self.length).astype(int)\n",
        "\n",
        "        # Collect indices by class\n",
        "        class_indices = {i: [] for i in range(len(self.original_data.classes))}\n",
        "        for idx in range(len(self.original_data)):\n",
        "            _, label = self.original_data[idx]\n",
        "            class_indices[label].append(idx)\n",
        "\n",
        "        # Build new dataset with rotated images\n",
        "        for cls, n_samples in enumerate(samples_per_class):\n",
        "            if n_samples == 0:\n",
        "                continue\n",
        "\n",
        "            # Randomly pick indices from this class\n",
        "            chosen_indices = rng.choice(class_indices[cls], size=n_samples, replace=True)\n",
        "\n",
        "            for i in chosen_indices:\n",
        "                pic, label = self.original_data[i]\n",
        "\n",
        "                # Apply random rotation\n",
        "                rotation_angle = rng.choice(rotations)\n",
        "                rotated_pic = rotate_picture(pic, rotation_angle)\n",
        "\n",
        "                # Convert to tensor if not already\n",
        "                if not isinstance(rotated_pic, torch.Tensor):\n",
        "                    rotated_pic = transforms.ToTensor()(rotated_pic)\n",
        "\n",
        "                # Move to GPU if specified\n",
        "                if self.device:\n",
        "                    rotated_pic = rotated_pic.to(self.device)\n",
        "\n",
        "                dataset.append((rotated_pic, label))\n",
        "\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwIf7da_yDf-"
      },
      "outputs": [],
      "source": [
        "rotated_data = RotateEuroSAT(data,\n",
        "                             length=10**4,\n",
        "                             shares=[1 / len(data.classes) for _ in data.classes],\n",
        "                             seed=42)\n",
        "\n",
        "train_data, test_data = random_split(rotated_data, [0.8, 0.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuDwG0K5hN8K"
      },
      "source": [
        "## Task 2: Implement a max pooling class and a CNN model(15 pt)\n",
        "Implement a classification model to predict the label of the faces in the dataset. You are free to experiment with the network architecture. However your model **must** contain:\n",
        "- At least one max pooling layer, implemented with `MyMaxPool`,\n",
        "- Convolutional, linear, and pooling layers only,\n",
        "- At least 3 convolutional layers, with at least two different kernel sizes,\n",
        "- A final output layer that is customizable to the number of classes that we want to predict.\n",
        "\n",
        "#### Briefly explain why you chose the particular architecture you implemented (around 2-3 sentences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVHQhPndvqKu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyMaxPool(nn.Sequential):\n",
        "\n",
        "  def __init__(self,\n",
        "               kernel_size,\n",
        "               stride=1,\n",
        "               padding=0):\n",
        "    super().__init__()\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride if stride else kernel_size\n",
        "    self.padding = padding\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Use PyTorch functional API for pooling\n",
        "    return F.max_pool2d(x, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n",
        "\n",
        "\n",
        "class MyCNNModel(nn.Sequential):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    # --- Convolutional layers with Batch Normalization ---\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    # --- Pooling layer ---\n",
        "    self.pool = MyMaxPool(kernel_size=2, stride=2)\n",
        "\n",
        "    # --- Fully connected layers ---\n",
        "    self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "    self.fc2 = nn.Linear(256, n_classes)\n",
        "\n",
        "    # --- Activation function ---\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Block 1: Conv + BN + ReLU + Pool\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    # Block 2: Conv + BN + ReLU + Pool\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    # Block 3: Conv + BN + ReLU + Pool\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOVl0a2kHupx",
        "outputId": "f77365f7-6b8b-4509-c354-c2b7a67e3540"
      },
      "outputs": [],
      "source": [
        "'''#TODO: print one iteration of your model to test its correctness'''\n",
        "my_model = MyCNNModel(n_classes=10)\n",
        "X, y = train_data[0]\n",
        "my_model(X[None, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APwe6Xkxntk5"
      },
      "source": [
        "The CNN consists of three convolutional layers with increasing channel depth (32, 64, 128) and alternating kernel sizes (3x3 and 5x5) to capture both fine-grained and coarse spatial features in the EuroSAT images. Each convolutional layer is followed by batch normalization, ReLU and max pooling to introduce non-linearity and reduce spatial dimensions. The flattened feature maps are passed through two fully connected layers that map the extracted representations to the final class predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6lasumGTkQ"
      },
      "source": [
        "## Training\n",
        "\n",
        "We define a `Trainer` function to train our model that returns avg loss and avg accuracy per epoch. We set the configuration of the trainer is set in the `cfg` dictionary. Use the trainer to train your model and make sure to print and plot avg loss and accuracy using the in-built commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsUHs5doTPD0"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cfg = {\n",
        "    'batch_size': 64,\n",
        "    'criterion': 'CrossEntropyLoss', #change to 'nn.NLLLoss' if you are applying a softmax in the last layer of your model\n",
        "    'epochs': 1,\n",
        "    'learning_rate': 0.001,\n",
        "    'optimizer':'Adam',\n",
        "    'seed':42,\n",
        "\n",
        "}\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, cfg):\n",
        "        self.model = model\n",
        "        self.cfg = cfg\n",
        "\n",
        "        for key, val in cfg.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "        self.optimizer = getattr(optim, self.optimizer)(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = getattr(nn, self.criterion)()\n",
        "\n",
        "\n",
        "    def iter_step(self, X, Y):\n",
        "        Y_pred = self.model(X)\n",
        "        loss = self.criterion(Y_pred, Y)\n",
        "        acc = (Y_pred.argmax(dim=-1) == Y).to(torch.float).mean()\n",
        "        return loss, acc\n",
        "\n",
        "    def train(self, dataset):\n",
        "        train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.manual_seed(self.seed))\n",
        "        avg_loss, avg_acc = [], []\n",
        "        tot_loss, tot_acc = 0, 0\n",
        "        for epoch in range(self.epochs):\n",
        "            iterdata = iter(train_dataloader)\n",
        "            train_size = len(iterdata)\n",
        "            pbar = tqdm(iterable=range(train_size))\n",
        "\n",
        "            for i in pbar:\n",
        "                batch = next(iterdata)\n",
        "                X_batch, Y_batch = batch #this is needed for compatibility with pbar\n",
        "                self.model.train()\n",
        "                self.optimizer.zero_grad()\n",
        "                loss, acc = self.iter_step(X_batch, Y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                tot_loss += loss.item()\n",
        "                tot_acc += acc.item()\n",
        "                avg_loss.append(tot_loss / max(1, len(avg_loss)))\n",
        "                avg_acc.append(tot_acc / max(1, len(avg_acc)))\n",
        "                desc = f'Epoch:{epoch} - Avg loss:{avg_loss[-1]:.5f} - Avg acc:{avg_acc[-1]:.5f}'\n",
        "                pbar.set_description(desc)\n",
        "\n",
        "        return avg_loss, avg_acc\n",
        "\n",
        "    def test(self, dataset):\n",
        "        avg_test_loss, avg_test_acc = [], []\n",
        "        test_loss, test_acc = 0, 0\n",
        "        self.model.eval()\n",
        "        test_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.manual_seed(self.seed))\n",
        "\n",
        "        for X_batch, Y_batch in iter(test_dataloader):\n",
        "            loss, acc = self.iter_step(X_batch, Y_batch)\n",
        "            test_loss += loss.item()\n",
        "            test_acc += acc\n",
        "            avg_test_loss.append(test_loss / max(1, len(avg_test_loss)))\n",
        "            avg_test_acc.append(test_acc / max(1, len(avg_test_acc)))\n",
        "\n",
        "        return avg_test_loss, avg_test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "3iDGmuiGksqP",
        "outputId": "a05513b2-b364-4222-8158-e52cc872d96f"
      },
      "outputs": [],
      "source": [
        "'''#TODO: train your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "my_trainer = Trainer(my_model, cfg)\n",
        "train_loss, train_acc = my_trainer.train(train_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(train_loss)), train_loss)\n",
        "ax1.plot(range(len(train_acc)), train_acc)\n",
        "ax0.set_title('Training loss')\n",
        "ax1.set_title('Training accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "JDfgU18pllpT",
        "outputId": "2230c4b6-9c47-47cd-97e8-7298cde1dfb8"
      },
      "outputs": [],
      "source": [
        "'''#TODO: test your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "test_loss, test_acc = my_trainer.test(test_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(test_loss)), test_loss)\n",
        "ax1.plot(range(len(test_acc)), test_acc)\n",
        "ax0.set_title('Test loss')\n",
        "ax1.set_title('Test accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN9ahBnqFkHc",
        "outputId": "fb3cded2-e001-4567-d36a-7f92b5f0f555"
      },
      "outputs": [],
      "source": [
        "# --- PERFORMANCE SUMMARY FOR MYCNNMODEL ---\n",
        "\n",
        "print(\"\\n=== MyCNNModel Performance Summary ===\")\n",
        "print(f\"Final Training Loss: {train_loss[-1]:.4f}\")\n",
        "print(f\"Final Training Accuracy: {train_acc[-1]*100:.2f}%\")\n",
        "print(f\"Final Test Loss: {test_loss[-1]:.4f}\")\n",
        "print(f\"Final Test Accuracy: {test_acc[-1]*100:.2f}%\")\n",
        "\n",
        "# Model architecture summary\n",
        "print(\"\\nModel Architecture:\\n\")\n",
        "print(my_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AvPUd76zVOk"
      },
      "source": [
        "## Task 3: Tune your training hyperparameters (optional, 10 pt)\n",
        "\n",
        "Implement a method <code>grid_search</code>, which looks for the best possible learning rates and training batch sizes for your model <code>MyCNNModel</code> and returns the best possible model, the corresponding training configuration, and the final training avg losses and accuracies (as numbers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJtGS3EB4NFy"
      },
      "outputs": [],
      "source": [
        "def grid_search(train_dataset, test_dataset, cfg,\n",
        "                learning_rates=[10**-1, 10**-2, 10**-3],\n",
        "                batch_sizes=[2**5, 2**6, 2**7]):\n",
        "\n",
        "    best_model = None\n",
        "    best_cfg = None\n",
        "    best_avg_acc = 0.0\n",
        "    best_avg_loss = float('inf')\n",
        "\n",
        "    # Try all learning rates and batch sizes\n",
        "    for lr in learning_rates:\n",
        "        for bs in batch_sizes:\n",
        "            print(f\"\\nTraining with learning rate={lr}, batch size={bs}\")\n",
        "\n",
        "            # Copy base configuration and update the current ones\n",
        "            current_cfg = cfg.copy()\n",
        "            current_cfg['learning_rate'] = lr\n",
        "            current_cfg['batch_size'] = bs\n",
        "\n",
        "            # Initialize a new model and trainer\n",
        "            model = MyCNNModel(n_classes=10)\n",
        "            trainer = Trainer(model, current_cfg)\n",
        "\n",
        "            # --- TRAINING PHASE ---\n",
        "            train_loss, train_acc = trainer.train(train_dataset)\n",
        "            # --- TEST PHASE ---\n",
        "            test_loss, test_acc = trainer.test(test_dataset)\n",
        "\n",
        "            # Compute final averages for both train and test\n",
        "            with torch.no_grad():\n",
        "                final_train_loss = np.mean(train_loss[-min(10, len(train_loss)):])\n",
        "                final_train_acc = np.mean(train_acc[-min(10, len(train_acc)):])\n",
        "                final_test_loss = np.mean(test_loss[-min(10, len(test_loss)):])\n",
        "                final_test_acc = np.mean(test_acc[-min(10, len(test_acc)):])\n",
        "\n",
        "            print(f\"  → Final Train Loss: {final_train_loss:.4f}, Train Acc: {final_train_acc:.4f}\")\n",
        "            print(f\"  → Final Test Loss: {final_test_loss:.4f}, Test Acc: {final_test_acc:.4f}\")\n",
        "\n",
        "            # --- Selection Criterion ---\n",
        "            if final_test_acc > best_avg_acc or (final_test_acc == best_avg_acc and final_test_loss < best_avg_loss):\n",
        "                best_model = model\n",
        "                best_cfg = current_cfg\n",
        "                best_avg_loss = final_test_loss\n",
        "                best_avg_acc = final_test_acc\n",
        "\n",
        "    print(\"\\n=== Best Configuration Found ===\")\n",
        "    print(f\"Learning Rate: {best_cfg['learning_rate']}, Batch Size: {best_cfg['batch_size']}\")\n",
        "    print(f\"Test Avg Loss: {best_avg_loss:.4f}, Test Avg Accuracy: {best_avg_acc:.4f}\")\n",
        "\n",
        "    return best_model, best_cfg, best_avg_loss, best_avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdHgFE5puuq-",
        "outputId": "53e9bc7f-b0ae-4e52-9238-20bc72c57547"
      },
      "outputs": [],
      "source": [
        "best_model, best_cfg, best_avg_loss, best_avg_acc = grid_search(\n",
        "    train_data, test_data, cfg,\n",
        "    learning_rates=[10**-1, 10**-2, 10**-3],\n",
        "    batch_sizes=[2**5, 2**6, 2**7]\n",
        ")\n",
        "\n",
        "print(f\"\\nBest model achieves Test Loss = {best_avg_loss:.2f} and Test Accuracy = {best_avg_acc:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLLCQpv14Gsx"
      },
      "source": [
        "## Task 4: Load and fine-tune a pre-trained model (10 pt)\n",
        "\n",
        "<ul>\n",
        "  <li>Load and train a pre-trained model for classification problems, such as those made available in <a href=\"https://huggingface.co/docs/timm\">Hugging Face's timm library</a>. </li>\n",
        "  <li> Make sure to modify the output layer to be compatible with the number of classes. </li>\n",
        "  <li>Print a summary of your results.</li>\n",
        "  <li>Briefly explain why you chose the particular architecture you did (around 2-3 sentences).</li>\n",
        "  </ul>\n",
        "  \n",
        "<b>Note</b>: in case you run into computing-related (e.g. memory) issues, consider choosing another model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8ec539ad82594c268c784ec69a5db5d3",
            "4b5d3a10f71243e683c489c8379282df",
            "5e4d219598cc4d549cc4789c10cc8dc6",
            "3bd80d87e89b413cb4afa9bf59028500",
            "60692c0b78f745a6b21af7d6b8fe2b20",
            "5927d7aad73c4f63b72de6b8c457b6b4",
            "00041143879d4ea4b8bb49e0e656e781",
            "f6dd800439e744bf9b030ea2607a7991",
            "fe1a39e26b67409d921f1e6d218c4fa9",
            "b7619756847f4b15b5d15f4efa5cbbfa",
            "9a804ffdf0f04cb282912a80415ad097"
          ]
        },
        "id": "ZIoc6F8rC88P",
        "outputId": "951c2af4-5b32-476d-e3ed-683e47c6a7f1"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "\n",
        "'''#TODO: import and fine-tune a pretrained model'''\n",
        "# create a small pretrained model and replace the head\n",
        "loaded_model = timm.create_model(\n",
        "    'resnet18', pretrained=True,\n",
        "    num_classes=10,\n",
        "    in_chans=3\n",
        ")\n",
        "loaded_trainer = Trainer(loaded_model, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "wXjFg5gNl1iO",
        "outputId": "a76531c1-f98f-41a7-d669-a9daec1365d2"
      },
      "outputs": [],
      "source": [
        "'''#TODO: train your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "train_loss, train_acc = loaded_trainer.train(train_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(train_loss)), train_loss)\n",
        "ax1.plot(range(len(train_acc)), train_acc)\n",
        "ax0.set_title('Training loss')\n",
        "ax1.set_title('Training accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "6JQYK__h0K-F",
        "outputId": "50380c6b-fdf0-4290-888c-2093949ecbed"
      },
      "outputs": [],
      "source": [
        "'''#TODO: test your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "test_loss, test_acc = loaded_trainer.test(test_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(test_loss)), test_loss)\n",
        "ax1.plot(range(len(test_acc)), test_acc)\n",
        "ax0.set_title('Test loss')\n",
        "ax1.set_title('Test accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AoJ0ZO0EZhB",
        "outputId": "ef4c8a4c-ab17-4dec-bd63-798a5149f92d"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Pre-trained Summary ===\")\n",
        "print(f\"Final Training Loss: {train_loss[-1]:.4f}\")\n",
        "print(f\"Final Training Accuracy: {train_acc[-1]*100:.2f}%\")\n",
        "print(f\"Final Test Loss: {test_loss[-1]:.4f}\")\n",
        "print(f\"Final Test Accuracy: {test_acc[-1]*100:.2f}%\")\n",
        "\n",
        "#print(\"\\nModel Architecture Summary:\")\n",
        "#print(timm.models.resnet.resnet18())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SAL8BQVEjIS"
      },
      "source": [
        "We fine-tuned ResNet-18, a lightweight residual convolutional neural network pre-trained on ImageNet, because it balances computational efficiency and strong generalization performance. Its residual skip connections help prevent vanishing gradients, making it effective even when fine-tuning on smaller datasets like EuroSAT. By only retraining the final layers, we leverage robust pre-learned feature extraction while adapting the model to the 10 land-cover classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkmytKNU_Z2"
      },
      "source": [
        "<a name=\"results-and-discussion\"></a>\n",
        "# Task  5: Results and discussion (5pt)\n",
        "\n",
        "Report the final metrics and make a few comments on the overall performance for the networks you implemented (3-4 lines).\n",
        "\n",
        "| Test metric         | your model | pre-trained model | your tuned model (optional) |\n",
        "|---------------------|--------------------|-------------------|-----------------------|\n",
        "| Accuracy (train)           |     52.62%         |      95.63%       |       52.44%         |                     \n",
        "| Loss (train)               |       1.4088        |     0.1537        |       1.4422         |    \n",
        "| Accuracy (test)           |     64.82%         |      91.78%       |       69.29%         |                     \n",
        "| Loss (test)               |     1.0411          |   0.3917          |        0.9798        |              \n",
        "             \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRJT6kh29IR"
      },
      "source": [
        "The results show that the pre-trained ResNet-18 significantly outperforms the custom CNN models, achieving over 91% test accuracy with a much lower loss, due to transfer learning and deep residual feature extraction.\n",
        "The custom CNN performs reasonably well given its simpler architecture, reaching around 65% test accuracy, but shows signs of underfitting due to limited capacity.\n",
        "After hyperparameter tuning, the CNN improves slightly to 69% test accuracy, indicating that better learning rates and batch sizes help optimize convergence but cannot match the robustness of a pre-trained model trained on large-scale ImageNet features."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00041143879d4ea4b8bb49e0e656e781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bd80d87e89b413cb4afa9bf59028500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7619756847f4b15b5d15f4efa5cbbfa",
            "placeholder": "​",
            "style": "IPY_MODEL_9a804ffdf0f04cb282912a80415ad097",
            "value": " 46.8M/46.8M [00:01&lt;00:00, 55.9MB/s]"
          }
        },
        "4b5d3a10f71243e683c489c8379282df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5927d7aad73c4f63b72de6b8c457b6b4",
            "placeholder": "​",
            "style": "IPY_MODEL_00041143879d4ea4b8bb49e0e656e781",
            "value": "model.safetensors: 100%"
          }
        },
        "5927d7aad73c4f63b72de6b8c457b6b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4d219598cc4d549cc4789c10cc8dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6dd800439e744bf9b030ea2607a7991",
            "max": 46807446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe1a39e26b67409d921f1e6d218c4fa9",
            "value": 46807446
          }
        },
        "60692c0b78f745a6b21af7d6b8fe2b20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec539ad82594c268c784ec69a5db5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b5d3a10f71243e683c489c8379282df",
              "IPY_MODEL_5e4d219598cc4d549cc4789c10cc8dc6",
              "IPY_MODEL_3bd80d87e89b413cb4afa9bf59028500"
            ],
            "layout": "IPY_MODEL_60692c0b78f745a6b21af7d6b8fe2b20"
          }
        },
        "9a804ffdf0f04cb282912a80415ad097": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7619756847f4b15b5d15f4efa5cbbfa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6dd800439e744bf9b030ea2607a7991": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1a39e26b67409d921f1e6d218c4fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
